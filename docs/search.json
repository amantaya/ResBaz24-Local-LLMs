[
  {
    "objectID": "Introduction-to-LLMs.html#what-are-large-language-models",
    "href": "Introduction-to-LLMs.html#what-are-large-language-models",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "What are Large Language Models?",
    "text": "What are Large Language Models?\n\nLarge Language Models (LLMs) are a subset of Deep Learning, which is a type of Machine Learning."
  },
  {
    "objectID": "Introduction-to-LLMs.html#machine-learning-vs.-artificial-intelligence",
    "href": "Introduction-to-LLMs.html#machine-learning-vs.-artificial-intelligence",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Machine Learning vs. Artificial Intelligence?",
    "text": "Machine Learning vs. Artificial Intelligence?\n\nMachine Learning is sometimes used interchangeably with the term Artificial Intelligence (AI), however machine learning typically refers to algorithms that can learn patterns from data and make predictions based on that data."
  },
  {
    "objectID": "Introduction-to-LLMs.html#machine-learning-vs.-artificial-intelligence-1",
    "href": "Introduction-to-LLMs.html#machine-learning-vs.-artificial-intelligence-1",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Machine Learning vs. Artificial Intelligence?",
    "text": "Machine Learning vs. Artificial Intelligence?\n\nMachine Learning is sometimes used interchangeably with the term Artificial Intelligence (AI), however machine learning typically refers to algorithms that can learn patterns from data and make predictions based on that data.\nMachine Learning is a subset of AI, which is a broader field that includes other types of algorithms that can perform tasks that typically require human intelligence."
  },
  {
    "objectID": "Introduction-to-LLMs.html#what-are-large-language-models-1",
    "href": "Introduction-to-LLMs.html#what-are-large-language-models-1",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "What are Large Language Models?",
    "text": "What are Large Language Models?\n\nLLMs refer to general purpose models that can be pre-trained and the fine-tuned for specific tasks."
  },
  {
    "objectID": "Introduction-to-LLMs.html#why-llms-are-a-hot-topic",
    "href": "Introduction-to-LLMs.html#why-llms-are-a-hot-topic",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Why LLMs Are a Hot Topic",
    "text": "Why LLMs Are a Hot Topic\n\nRelatively new - GPT-1 (117 million parameters) was released in 2018"
  },
  {
    "objectID": "Introduction-to-LLMs.html#why-llms-are-a-hot-topic-1",
    "href": "Introduction-to-LLMs.html#why-llms-are-a-hot-topic-1",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Why LLMs Are a Hot Topic",
    "text": "Why LLMs Are a Hot Topic\n\nRelatively new - GPT-1 (117 million parameters) was released in 2018\nPerform well on wide-variety of language tasks that have traditionally been difficult for computers to solve (e.g. question answering, summarization, translation)"
  },
  {
    "objectID": "Introduction-to-LLMs.html#why-llms-are-a-hot-topic-2",
    "href": "Introduction-to-LLMs.html#why-llms-are-a-hot-topic-2",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Why LLMs Are a Hot Topic",
    "text": "Why LLMs Are a Hot Topic\n\nRelatively new - GPT-1 (117 million parameters) was released in 2018\nPerform well on wide-variety of language tasks that have traditionally been difficult for computers to solve (e.g. question answering, summarization, translation)\nCan be fine-tuned to solve specific problems in different domains"
  },
  {
    "objectID": "Introduction-to-LLMs.html#why-llms-are-a-hot-topic-3",
    "href": "Introduction-to-LLMs.html#why-llms-are-a-hot-topic-3",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Why LLMs Are a Hot Topic",
    "text": "Why LLMs Are a Hot Topic\n\nRelatively new - GPT-1 (117 million parameters) was released in 2018\nPerform well on wide-variety of language tasks that have traditionally been difficult for computers to solve (e.g. question answering, summarization, translation)\nCan be fine-tuned to solve specific problems in different domains\nRecent software innovations (e.g., Transformers) and computational improvements have made training on vast data sets possible"
  },
  {
    "objectID": "Introduction-to-LLMs.html#main-characteristics-of-llms",
    "href": "Introduction-to-LLMs.html#main-characteristics-of-llms",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "3 Main Characteristics of LLMs",
    "text": "3 Main Characteristics of LLMs\n\nLarge\nGeneral Purpose\nPre-trained and Fine-tuned"
  },
  {
    "objectID": "Introduction-to-LLMs.html#how-large-are-llms",
    "href": "Introduction-to-LLMs.html#how-large-are-llms",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "How “Large” are LLMs?",
    "text": "How “Large” are LLMs?\n\nThe size of LLMs is typically measured in the number of parameters\nThere are over 50 models &gt; 1 billion parameters.1\nTraining data is typically petabytes in size\n\nhttps://matt-rickard.com/a-list-of-1-billion-parameter-llms"
  },
  {
    "objectID": "Introduction-to-LLMs.html#general-purpose",
    "href": "Introduction-to-LLMs.html#general-purpose",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "General Purpose",
    "text": "General Purpose\nGeneral Purpose means the model can be used to solve a wide variety of general language problems."
  },
  {
    "objectID": "Introduction-to-LLMs.html#pre-trained",
    "href": "Introduction-to-LLMs.html#pre-trained",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Pre-trained",
    "text": "Pre-trained\nPre-trained means the model has been trained on a large amount of text data to solve common language problems, such as:\n\ntext classification and generation\nquestion answering\nsummarizing documents\ngenerating code\ntranslating languages"
  },
  {
    "objectID": "Introduction-to-LLMs.html#fine-tuned",
    "href": "Introduction-to-LLMs.html#fine-tuned",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Fine-tuned",
    "text": "Fine-tuned\nFine-tuned means the model has been trained on a small* amount of domain data to solve a specific problem in different domains, such as:\n\nlegal\nmedical\nfinance\nscientific\n\n*small is relative to the amount of data used to pre-train the model."
  },
  {
    "objectID": "Introduction-to-LLMs.html#example-llms",
    "href": "Introduction-to-LLMs.html#example-llms",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Example LLMs",
    "text": "Example LLMs\nHere’s a non-comprehensive list of some of the largest models:\n\n\n\nModel\nParameters\nCompany\nOpen-Source?\n\n\n\n\nGPT-4\n1.76 trillion 1\nOpenAI\nNo\n\n\nGPT-3\n175 billion\nOpenAI\nNo\n\n\nPaLM 2\n340 billion\nGoogle\nYes\n\n\nLlama 3\n70 billion\nMeta\nYes\n\n\nmistral-7B\n7 billion\nMistral AI\nYes\n\n\n\nhttps://the-decoder.com/gpt-4-has-a-trillion-parameters/"
  },
  {
    "objectID": "Introduction-to-LLMs.html#types-of-llms",
    "href": "Introduction-to-LLMs.html#types-of-llms",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Types of LLMs",
    "text": "Types of LLMs\n\nGeneric Language Models - predict the next token/word base on the training data"
  },
  {
    "objectID": "Introduction-to-LLMs.html#types-of-llms-1",
    "href": "Introduction-to-LLMs.html#types-of-llms-1",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Types of LLMs",
    "text": "Types of LLMs\n\nGeneric Language Models - predict the next token/word base on the training data\nInstruction-Tuned - predict a response to instructions given in the input/prompt"
  },
  {
    "objectID": "Introduction-to-LLMs.html#types-of-llms-2",
    "href": "Introduction-to-LLMs.html#types-of-llms-2",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Types of LLMs",
    "text": "Types of LLMs\n\nGeneric Language Models - predict the next token/word base on the training data\nInstruction-Tuned - predict a response to instructions given in the input/prompt\nDialouge-Tuned - type of Instruction-Tuned that peforms conversational question/answer response"
  },
  {
    "objectID": "Introduction-to-LLMs.html#selecting-a-model",
    "href": "Introduction-to-LLMs.html#selecting-a-model",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Selecting a Model",
    "text": "Selecting a Model\nConsider the following when selecting a model:\n\nSize - larger models typically perform better, but require more computational resources (GPU, memory, etc.)\nTask - some models are better suited for specific tasks (e.g. summarization, translation, question/answer)\nLicense - some models are proprietary and require a license"
  },
  {
    "objectID": "Introduction-to-LLMs.html#ollama",
    "href": "Introduction-to-LLMs.html#ollama",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Ollama",
    "text": "Ollama\n\nollama is an executable that allows you to run LLMs locally on your machine\nChoose from a variety of open-source models and sizes (e.g., llama3, mistral-7B, gemma)\nEach model has an API that allows you to interact with the model programmatically\nFewer models than HuggingFace, but easier to use\n\nWebsite: https://ollama.com/"
  },
  {
    "objectID": "Introduction-to-LLMs.html#huggingface",
    "href": "Introduction-to-LLMs.html#huggingface",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "HuggingFace",
    "text": "HuggingFace\n\nHosts a huge variety of pre-trained models, including:\n\nLLMs\nImage Classification\nObject Detection\nText-to-Speech\n\nMost models use the transformers library in Python\nGenerally harder to use than ollama (especially for beginners)\n\nWebsite: https://huggingface.co/"
  },
  {
    "objectID": "Introduction-to-LLMs.html#downloading-and-running-ollama",
    "href": "Introduction-to-LLMs.html#downloading-and-running-ollama",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Downloading and Running ollama",
    "text": "Downloading and Running ollama\n\nDownload the ollama executable from the website\nRun the executable in the terminal/shell with the name of the model you want to run\n\nollama run llama3"
  },
  {
    "objectID": "Introduction-to-LLMs.html#code",
    "href": "Introduction-to-LLMs.html#code",
    "title": "Introduction to Running LLMs - Locally!",
    "section": "Code",
    "text": "Code\nWhen you click the Render button a presentation will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\n[1] 2"
  }
]