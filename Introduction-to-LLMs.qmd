---
title: "Introduction to Running LLMs - Locally!"
author: "Andrew Antaya"
format: revealjs
---

## What are Large Language Models?

- Large Language Models (LLMs) are a subset of **Deep Learning**,
  which is a type of **Machine Learning**.

## Machine Learning vs. Artificial Intelligence?

-   ***Machine Learning*** is sometimes used interchangeably with the term
    ***Artificial Intelligence*** **(AI)**, however machine learning typically
    refers to algorithms that can learn patterns from data and make
    predictions based on that data.
    
## Machine Learning vs. Artificial Intelligence?

-   ***Machine Learning*** is sometimes used interchangeably with the term
    ***Artificial Intelligence*** **(AI)**, however machine learning typically
    refers to algorithms that can learn patterns from data and make
    predictions based on that data.
-   ***Machine Learning*** is a subset of **AI**, which is a broader field
    that includes other types of algorithms that can perform tasks that
    typically require human intelligence.

## What are Large Language Models?

- LLMs refer to *general purpose* models that can be ***pre-trained***
  and the ***fine-tuned*** for specific tasks.

## Why LLMs Are a Hot Topic

-   Relatively new - GPT-1 (117 million parameters) was released in 2018 

## Why LLMs Are a Hot Topic

-   Relatively new - GPT-1 (117 million parameters) was released in 2018 
-   Perform well on wide-variety of language tasks that have traditionally been difficult for computers to solve (e.g. question answering, summarization, translation)

## Why LLMs Are a Hot Topic

-   Relatively new - GPT-1 (117 million parameters) was released in 2018 
-   Perform well on wide-variety of language tasks that have traditionally been difficult for computers to solve (e.g. question answering, summarization, translation)
-   Can be fine-tuned to solve specific problems in different domains

## Why LLMs Are a Hot Topic

-   Relatively new - GPT-1 (117 million parameters) was released in 2018 
-   Perform well on wide-variety of language tasks that have traditionally been difficult for computers to solve (e.g. question answering, summarization, translation)
-   Can be fine-tuned to solve specific problems in different domains
-   Recent software innovations (e.g., Transformers) and computational improvements have made training on vast data sets possible

## 3 Main Characteristics of LLMs

1.  Large
2.  General Purpose
3.  Pre-trained and Fine-tuned

## How "Large" are LLMs?

-   The size of LLMs is typically measured in the number of parameters

-   There are over 50 models \> 1 billion parameters.[^1]

-   Training data is typically petabytes in size

## General PurposeK

***General Purpose*** means the model can be used to solve a wide
variety of general language problems.

## Pre-trained

***Pre-trained*** means the model has been trained on a large amount of
text data to solve common language problems, such as:

-   text classification and generation
-   question answering
-   summarizing documents
-   generating code
-   translating languages

## Fine-tuned

***Fine-tuned*** means the model has been trained on a **small\*** amount
of domain data to solve a specific problem in different domains, such
as:

-   legal
-   medical
-   finance
-   scientific

**\*small** is relative to the amount of data used to pre-train the
model.

## Example LLMs

Here's a non-comprehensive list of some of the largest models:

| Model      | Parameters         | Company    | Open-Source? |
|------------|--------------------|------------|--------------|
| GPT-4      | 1.76 trillion [^2] | OpenAI     | No           |
| GPT-3      | 175 billion        | OpenAI     | No           |
| PaLM 2     | 340 billion        | Google     | Yes          |
| Llama 3    | 70 billion         | Meta       | Yes          |
| mistral-7B | 7 billion          | Mistral AI | Yes          |

## Types of LLMs

-   **Generic Language Models** - predict the next token/word base on
    the training data

-   **Instruction-Tuned** - predict a response to instructions given in
    the input/prompt

-   **Dialouge-Tuned** - type of *Instruction-Tuned* that peforms
    conversational question/answer response

## Selecting a Model

Consider the following when selecting a model:

-   **Size** - larger models typically perform better, but require more
    computational resources
-   **Task** - some models are better suited for specific tasks
-   **License** - some models are proprietary and require a license

## Ollama

-   `ollama` is an executable that allows you to run LLMs locally on your
  machine
-   Options to choose from a variety of open-source models
-   Each model has an API that allows you to interact with the model programmatically

Website: [https://ollama.com/](https://ollama.com/)

## Code

When you click the **Render** button a presentation will be generated
that includes both content and the output of embedded code. You can
embed code like this:

```{r}
1 + 1
```

[^1]: https://matt-rickard.com/a-list-of-1-billion-parameter-llms

[^2]: https://the-decoder.com/gpt-4-has-a-trillion-parameters/
